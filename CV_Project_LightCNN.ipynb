{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_Project_LightCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CV Project - Face Recognize with Light CNN"
      ],
      "metadata": {
        "id": "FBKW4kqNQw4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0 - Paper Resources"
      ],
      "metadata": {
        "id": "gwKtS4M_Q7uA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cZ2qHi9WEB2W"
      },
      "outputs": [],
      "source": [
        "# GitHub https://github.com/AlfredXiangWu/LightCNN\n",
        "# Paper  https://arxiv.org/pdf/1511.02683v4.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - imports & Hyper-parameters"
      ],
      "metadata": {
        "id": "UKFNDY_yRRu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets"
      ],
      "metadata": {
        "id": "siUdARQ_S2s5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "TEST_RATIO = 0.2\n",
        "\n",
        "# training\n",
        "EPOCHS = 5\n",
        "BS = 128             # batch size\n",
        "LR = 0.0001         # learning rate\n",
        "\n",
        "ROOT = \"./\"\n",
        "TRAIN_LIST = \"./train_list.txt\"\n",
        "VALID_LIST = \"./vaild_list.txt\"\n",
        "NUM_CLASSES = 5749\n",
        "NUM_WORKER = 2\n",
        "PRINT_FREQUENCY = 10"
      ],
      "metadata": {
        "id": "wwEc42w8RRWg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - DataSet & DataLoader"
      ],
      "metadata": {
        "id": "Tgw0iEMVREV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "這邊會下載人臉圖片 dataset，然後處理成符合 Model Input 的形式"
      ],
      "metadata": {
        "id": "AQxtZ49j731z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random, math\n",
        "from PIL import Image\n",
        "from pathlib import Path as Path\n",
        "\n",
        "# download dataset and extract\n",
        "# !git clone https://github.com/AlfredXiangWu/LightCNN\n",
        "!wget -c http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
        "\n",
        "\n",
        "dataset_dir = Path('./lfw')\n",
        "if not dataset_dir.exists():\n",
        "    !tar -xf lfw.tgz\n",
        "\n",
        "# load data into dict\n",
        "dataset = []\n",
        "num_classes = 0\n",
        "for index, catdir in enumerate(dataset_dir.glob(\"*\")):\n",
        "    # iterate each file in this dir\n",
        "    for pth in catdir.glob(\"*\"):\n",
        "        dataset.append((pth,index))\n",
        "    num_classes += 1\n",
        "random.shuffle(dataset)\n",
        "\n",
        "# split dataset\n",
        "train_size = math.floor( len(dataset) * 0.8 )\n",
        "valid_size = len(dataset) - train_size\n",
        "\n",
        "# save to file\n",
        "with open('./train_list.txt', 'w') as f:\n",
        "    for img, cat in dataset[:train_size]:\n",
        "        f.write(f'{img} {cat}\\n')\n",
        "\n",
        "with open('./vaild_list.txt', 'w') as f:\n",
        "    for img, cat in dataset[train_size:]:\n",
        "        f.write(f'{img} {cat}\\n')"
      ],
      "metadata": {
        "id": "c8WE23U879ZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0ba1d1-45f4-40e3-da2c-374d0db843ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-16 12:41:10--  http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
            "Resolving vis-www.cs.umass.edu (vis-www.cs.umass.edu)... 128.119.244.95\n",
            "Connecting to vis-www.cs.umass.edu (vis-www.cs.umass.edu)|128.119.244.95|:80... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataSet"
      ],
      "metadata": {
        "id": "aeYY8r7776DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "def default_loader(path):\n",
        "    img = Image.open(path).convert('L')\n",
        "    return img\n",
        "\n",
        "def default_list_reader(fileList):\n",
        "    imgList = []\n",
        "    with open(fileList, 'r') as file:\n",
        "        for line in file.readlines():\n",
        "            imgPath, label = line.strip().split(' ')\n",
        "            imgList.append((imgPath, int(label)))\n",
        "    return imgList\n",
        "\n",
        "class ImageList(data.Dataset):\n",
        "    def __init__(self, root, fileList, transform=None, list_reader=default_list_reader, loader=default_loader):\n",
        "        self.root      = root\n",
        "        self.imgList   = list_reader(fileList)\n",
        "        self.transform = transform\n",
        "        self.loader    = loader\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        imgPath, target = self.imgList[index]\n",
        "        img = self.loader(os.path.join(self.root, imgPath))\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgList)\n",
        "\n",
        "\n",
        "#load image\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    ImageList(root=ROOT, fileList=TRAIN_LIST, \n",
        "        transform=transforms.Compose([ \n",
        "            transforms.RandomCrop(128),\n",
        "            transforms.RandomHorizontalFlip(), \n",
        "            transforms.ToTensor(),\n",
        "        ])),\n",
        "    batch_size=BS, shuffle=True,\n",
        "    num_workers=NUM_WORKER, pin_memory=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    ImageList(root=ROOT, fileList=VALID_LIST, \n",
        "        transform=transforms.Compose([ \n",
        "            transforms.CenterCrop(128),\n",
        "            transforms.ToTensor(),\n",
        "        ])),\n",
        "    batch_size=BS, shuffle=False,\n",
        "    num_workers=NUM_WORKER, pin_memory=True)   "
      ],
      "metadata": {
        "id": "oylTNBo4Qvph"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - Model Architecture"
      ],
      "metadata": {
        "id": "Ml5G9daxRi2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "O8gVCkoZTzRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    implement Light CNN\n",
        "    @author: Alfred Xiang Wu\n",
        "    @date: 2017.07.04\n",
        "'''\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class mfm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, type=1):\n",
        "        super(mfm, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        if type == 1:\n",
        "            self.filter = nn.Conv2d(in_channels, 2*out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        else:\n",
        "            self.filter = nn.Linear(in_channels, 2*out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.filter(x)\n",
        "        out = torch.split(x, self.out_channels, 1)\n",
        "        return torch.max(out[0], out[1])\n",
        "\n",
        "class group(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        super(group, self).__init__()\n",
        "        self.conv_a = mfm(in_channels, in_channels, 1, 1, 0)\n",
        "        self.conv   = mfm(in_channels, out_channels, kernel_size, stride, padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_a(x)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class resblock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(resblock, self).__init__()\n",
        "        self.conv1 = mfm(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = mfm(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = out + res\n",
        "        return out\n",
        "\n",
        "class network_9layers(nn.Module):\n",
        "    def __init__(self, num_classes=79077):\n",
        "        super(network_9layers, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            mfm(1, 48, 5, 1, 2), \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True), \n",
        "            group(48, 96, 3, 1, 1), \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n",
        "            group(96, 192, 3, 1, 1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True), \n",
        "            group(192, 128, 3, 1, 1),\n",
        "            group(128, 128, 3, 1, 1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n",
        "            )\n",
        "        self.fc1 = mfm(8*8*128, 256, type=0)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        out = self.fc2(x)\n",
        "        return out, x\n",
        "\n",
        "class network_29layers(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=79077):\n",
        "        super(network_29layers, self).__init__()\n",
        "        self.conv1  = mfm(1, 48, 5, 1, 2)\n",
        "        self.pool1  = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
        "        self.block1 = self._make_layer(block, layers[0], 48, 48)\n",
        "        self.group1 = group(48, 96, 3, 1, 1)\n",
        "        self.pool2  = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
        "        self.block2 = self._make_layer(block, layers[1], 96, 96)\n",
        "        self.group2 = group(96, 192, 3, 1, 1)\n",
        "        self.pool3  = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
        "        self.block3 = self._make_layer(block, layers[2], 192, 192)\n",
        "        self.group3 = group(192, 128, 3, 1, 1)\n",
        "        self.block4 = self._make_layer(block, layers[3], 128, 128)\n",
        "        self.group4 = group(128, 128, 3, 1, 1)\n",
        "        self.pool4  = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n",
        "        self.fc     = mfm(8*8*128, 256, type=0)\n",
        "        self.fc2    = nn.Linear(256, num_classes)\n",
        "            \n",
        "    def _make_layer(self, block, num_blocks, in_channels, out_channels):\n",
        "        layers = []\n",
        "        for i in range(0, num_blocks):\n",
        "            layers.append(block(in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.block1(x)\n",
        "        x = self.group1(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.block2(x)\n",
        "        x = self.group2(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.block3(x)\n",
        "        x = self.group3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.group4(x)\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        fc = self.fc(x)\n",
        "        fc = F.dropout(fc, training=self.training)\n",
        "        out = self.fc2(fc)\n",
        "        return out, fc\n",
        "\n",
        "\n",
        "class network_29layers_v2(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=79077):\n",
        "        super(network_29layers_v2, self).__init__()\n",
        "        self.conv1    = mfm(1, 48, 5, 1, 2)\n",
        "        self.block1   = self._make_layer(block, layers[0], 48, 48)\n",
        "        self.group1   = group(48, 96, 3, 1, 1)\n",
        "        self.block2   = self._make_layer(block, layers[1], 96, 96)\n",
        "        self.group2   = group(96, 192, 3, 1, 1)\n",
        "        self.block3   = self._make_layer(block, layers[2], 192, 192)\n",
        "        self.group3   = group(192, 128, 3, 1, 1)\n",
        "        self.block4   = self._make_layer(block, layers[3], 128, 128)\n",
        "        self.group4   = group(128, 128, 3, 1, 1)\n",
        "        self.fc       = nn.Linear(8*8*128, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes, bias=False)\n",
        "            \n",
        "    def _make_layer(self, block, num_blocks, in_channels, out_channels):\n",
        "        layers = []\n",
        "        for i in range(0, num_blocks):\n",
        "            layers.append(block(in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.max_pool2d(x, 2) + F.avg_pool2d(x, 2)\n",
        "\n",
        "        x = self.block1(x)\n",
        "        x = self.group1(x)\n",
        "        x = F.max_pool2d(x, 2) + F.avg_pool2d(x, 2)\n",
        "\n",
        "        x = self.block2(x)\n",
        "        x = self.group2(x)\n",
        "        x = F.max_pool2d(x, 2) + F.avg_pool2d(x, 2)\n",
        "\n",
        "        x = self.block3(x)\n",
        "        x = self.group3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.group4(x)\n",
        "        x = F.max_pool2d(x, 2) + F.avg_pool2d(x, 2)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        fc = self.fc(x)\n",
        "        x = F.dropout(fc, training=self.training)\n",
        "        out = self.fc2(x)\n",
        "        return out, fc\n",
        "\n",
        "def LightCNN_9Layers(**kwargs):\n",
        "    model = network_9layers(**kwargs)\n",
        "    return model\n",
        "\n",
        "def LightCNN_29Layers(**kwargs):\n",
        "    model = network_29layers(resblock, [1, 2, 3, 4], **kwargs)\n",
        "    return model\n",
        "\n",
        "def LightCNN_29Layers_v2(**kwargs):\n",
        "    model = network_29layers_v2(resblock, [1, 2, 3, 4], **kwargs)\n",
        "    return model\n",
        "\n",
        "model = LightCNN_9Layers()"
      ],
      "metadata": {
        "id": "ZyZAvqZ6Rijd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "etAsgEM4Tt6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LR)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    criterion.cuda()"
      ],
      "metadata": {
        "id": "LRf6JscKTyUy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - Training & Validation"
      ],
      "metadata": {
        "id": "Jf9gW0y9RJi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy and AverageMeter"
      ],
      "metadata": {
        "id": "bm-t86hP5307"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val   = 0\n",
        "        self.avg   = 0\n",
        "        self.sum   = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val   = val\n",
        "        self.sum   += val * n\n",
        "        self.count += n\n",
        "        self.avg   = self.sum / self.count"
      ],
      "metadata": {
        "id": "-svFymVW67pK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred    = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    # correct_k = correct[:k].view(-1).float().sum(0)\n",
        "    # res = correct_k.mul_(100.0 / batch_size)\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "def save_checkpoint(state, filename):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    scale = 0.457305051927326\n",
        "    step  = 10\n",
        "    lr = LR * (scale ** (epoch // step))\n",
        "    print('lr: {}'.format(lr))\n",
        "    if (epoch != 0) & (epoch % step == 0):\n",
        "        print('Change lr')\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = param_group['lr'] * scale\n"
      ],
      "metadata": {
        "id": "JKODEHU853e8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "obUXZ0xaRpb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time  = AverageMeter()\n",
        "    losses     = AverageMeter()\n",
        "    top1       = AverageMeter()\n",
        "    top5       = AverageMeter()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input      = input.cuda()\n",
        "        target     = target.cuda()\n",
        "        input_var  = torch.autograd.Variable(input)\n",
        "        target_var = torch.autograd.Variable(target)\n",
        "\n",
        "        # compute output\n",
        "        output, _ = model(input_var)\n",
        "        loss   = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target)\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(prec1[0], input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % PRINT_FREQUENCY == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
        "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
        "                   epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                   data_time=data_time, loss=losses, top1=top1, top5=top5))"
      ],
      "metadata": {
        "id": "TrPO81UgRpDJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ],
      "metadata": {
        "id": "0SqIqYKPRrRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(val_loader, model, criterion):\n",
        "    batch_time = AverageMeter()\n",
        "    losses     = AverageMeter()\n",
        "    top1       = AverageMeter()\n",
        "    top5       = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "            input      = input.cuda()\n",
        "            target     = target.cuda()\n",
        "            \n",
        "            input_var  = torch.autograd.Variable(input)\n",
        "            target_var = torch.autograd.Variable(target)\n",
        "\n",
        "            # compute output\n",
        "            output, _ = model(input_var)\n",
        "            loss   = criterion(output, target_var)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec1 = accuracy(output.data, target)\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(prec1[0], input.size(0))\n",
        "\n",
        "\n",
        "    print('\\nTest set: Average loss: {}, Accuracy: ({})\\n'.format(losses.avg, top1.avg))\n",
        "\n",
        "    return top1.avg"
      ],
      "metadata": {
        "id": "_1sNNSvURubd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN CODE"
      ],
      "metadata": {
        "id": "IMAj4zd_RNWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# large lr for last fc parameters\n",
        "params = []\n",
        "for name, value in model.named_parameters():\n",
        "    if 'bias' in name:\n",
        "        if 'fc2' in name:\n",
        "            params += [{'params':value, 'lr': 20 * LR, 'weight_decay': 0}]\n",
        "        else:\n",
        "            params += [{'params':value, 'lr': 2 * LR, 'weight_decay': 0}]\n",
        "    else:\n",
        "        if 'fc2' in name:\n",
        "            params += [{'params':value, 'lr': 10 * LR}]\n",
        "        else:\n",
        "            params += [{'params':value, 'lr': 1 * LR}]\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = torch.nn.DataParallel(model).cuda()\n",
        "\n",
        "print(model)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "\n",
        "validate(val_loader, model, criterion)    \n",
        "\n",
        "for epoch in range(0, EPOCHS):\n",
        "\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "    # train for one epoch\n",
        "    train(train_loader, model, criterion, optimizer, epoch)\n",
        "\n",
        "    # evaluate on validation set\n",
        "    prec1 = validate(val_loader, model, criterion)\n",
        "\n",
        "    # checkpoint\n",
        "    # save_name = args.save_path + 'lightCNN_' + str(epoch+1) + '_checkpoint.pth.tar'\n",
        "    # save_checkpoint({\n",
        "    #     'epoch': epoch + 1,\n",
        "    #     'arch': args.arch,\n",
        "    #     'state_dict': model.state_dict(),\n",
        "    #     'prec1': prec1,\n",
        "    # }, save_name)"
      ],
      "metadata": {
        "id": "-3LXN7cdR19u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf8bfe3-0a82-46d4-edf8-8b6d875cc7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataParallel(\n",
            "  (module): network_9layers(\n",
            "    (features): Sequential(\n",
            "      (0): mfm(\n",
            "        (filter): Conv2d(1, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      )\n",
            "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "      (2): group(\n",
            "        (conv_a): mfm(\n",
            "          (filter): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (conv): mfm(\n",
            "          (filter): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "      (4): group(\n",
            "        (conv_a): mfm(\n",
            "          (filter): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (conv): mfm(\n",
            "          (filter): Conv2d(96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "      (6): group(\n",
            "        (conv_a): mfm(\n",
            "          (filter): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (conv): mfm(\n",
            "          (filter): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (7): group(\n",
            "        (conv_a): mfm(\n",
            "          (filter): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (conv): mfm(\n",
            "          (filter): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    )\n",
            "    (fc1): mfm(\n",
            "      (filter): Linear(in_features=8192, out_features=512, bias=True)\n",
            "    )\n",
            "    (fc2): Linear(in_features=256, out_features=79077, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Test set: Average loss: 11.280811631548932, Accuracy: (0.0)\n",
            "\n",
            "lr: 0.0001\n",
            "Epoch: [0][0/83]\tTime 4.594 (4.594)\tData 0.633 (0.633)\tLoss 11.2779 (11.2779)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            "Epoch: [0][10/83]\tTime 0.649 (0.969)\tData 0.000 (0.061)\tLoss 11.2111 (11.2555)\tPrec@1 1.562 (1.562)\tPrec@5 0.000 (0.000)\n",
            "Epoch: [0][20/83]\tTime 0.645 (0.817)\tData 0.000 (0.055)\tLoss 11.0326 (11.1969)\tPrec@1 3.125 (2.641)\tPrec@5 0.000 (0.000)\n",
            "Epoch: [0][30/83]\tTime 0.650 (0.763)\tData 0.000 (0.053)\tLoss 10.9745 (11.1336)\tPrec@1 3.906 (3.226)\tPrec@5 0.000 (0.000)\n",
            "Epoch: [0][40/83]\tTime 0.654 (0.736)\tData 0.000 (0.052)\tLoss 10.8547 (11.0534)\tPrec@1 3.125 (3.563)\tPrec@5 0.000 (0.000)\n",
            "Epoch: [0][50/83]\tTime 0.653 (0.719)\tData 0.000 (0.051)\tLoss 10.4246 (10.9806)\tPrec@1 4.688 (3.569)\tPrec@5 0.000 (0.000)\n",
            "Epoch: [0][60/83]\tTime 0.647 (0.708)\tData 0.000 (0.051)\tLoss 10.4139 (10.9026)\tPrec@1 6.250 (3.599)\tPrec@5 0.000 (0.000)\n",
            "Epoch: [0][70/83]\tTime 0.645 (0.700)\tData 0.000 (0.050)\tLoss 10.3812 (10.8266)\tPrec@1 3.125 (3.675)\tPrec@5 0.000 (0.000)\n",
            "Epoch: [0][80/83]\tTime 0.650 (0.694)\tData 0.000 (0.050)\tLoss 10.3339 (10.7501)\tPrec@1 1.562 (3.800)\tPrec@5 0.000 (0.000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0][1])\n",
        "Image.open(dataset[0][0])"
      ],
      "metadata": {
        "id": "cOlpCj1YPj45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}