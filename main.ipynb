{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Project Jupyter Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Project From ( Optional )\n",
    "\n",
    "如果是用 Colab 開啟此 GitHub 檔案的話，請將 PullFromRepo 設成 True，他會自動 Pull 對應 branch 的其他檔案下來（主要是 functional.py 以及 light_cnn.py 兩個檔案作為 dependency）。\n",
    "\n",
    "如果是使用 git clone 整個專案到 local 上的話，則不需要 PullFromRepo（預設為此）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PullFromRepo = False\n",
    "DoDownload = False\n",
    "ImageTrick = False\n",
    "\n",
    "if PullFromRepo:\n",
    "    !git init\n",
    "    !git remote add origin \"https://github.com/freshLiver/CV_PROJECT\"\n",
    "    !git pull origin py-test\n",
    "\n",
    "    %pip install gdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "下載資料集以及其他 training 所需的 packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from os import system\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from functional import TrainingHelper, ImageList\n",
    "from light_cnn import LightCNN_9Layers as LightCNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters\n",
    "\n",
    "訓練所需的參數以及資料集路徑設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "EPOCHS = 10\n",
    "BS = 256             # batch size\n",
    "LR = 0.001          # learning rate\n",
    "NUM_WORKER = 0\n",
    "PRINT_FREQUENCY = 10\n",
    "VALID_RATIO = 0.2\n",
    "\n",
    "\n",
    "# give me abs path as ROOT(work dir)\n",
    "ROOT = Path.home().joinpath(\"Downloads\")\n",
    "\n",
    "# dataset paths\n",
    "\n",
    "# DATA_SRC = \"https://drive.google.com/uc?id=11zQKShQ_qTt5HJtZDpkvskPXuDb2rbbo\"\n",
    "DATA_SRC = \"https://drive.google.com/uc?id=11KFpKd8i8r1nES1AmSminorvRivB2M8_\"\n",
    "\n",
    "DATA_DST = ROOT.joinpath(\"vggface2-test.zip\")\n",
    "DATA_DIR = ROOT.joinpath(\"vggface2\")\n",
    "\n",
    "\n",
    "TRAIN_LIST = ROOT.joinpath(\"train_list.txt\")\n",
    "VALID_LIST = ROOT.joinpath(\"valid_list.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Unzip Dataset ( Optional )\n",
    "\n",
    "由於 vggface2 的 dataset 是放在我的 google drive 上，因此這邊會使用 gdown 下載資料集到前面設定的路徑（ROOT）下並解壓縮，若已經有下載 dataset 的話請在上面設定路徑，並不要執行這邊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DoDownload:\n",
    "\n",
    "    # download dataset\n",
    "    gdown.download(str(DATA_SRC), str(DATA_DST), False)\n",
    "\n",
    "    # extract if dir not exists\n",
    "    if not DATA_DIR.exists():\n",
    "        system(f\"unzip -d {DATA_DIR} {DATA_DST} > unzip.log\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Trick (Optional)\n",
    "\n",
    "直接對原始圖片進行一些特別的處理，並複寫原圖片以在 Dataset 讀寫時減少運算量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ImageTrick:\n",
    "\n",
    "    # visit each dir under data dir\n",
    "    for subdir in DATA_DIR.glob(\"*\"):\n",
    "\n",
    "        # visit all files under this dir\n",
    "        for imgPath in subdir.glob(\"*\"):\n",
    "\n",
    "            # load img\n",
    "            origin = cv2.imread(str(imgPath), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # do canny on original image\n",
    "            edges = cv2.Canny(origin, 150, 150)\n",
    "            res = cv2.bitwise_or(origin, edges)\n",
    "\n",
    "            # overwrite original image\n",
    "            cv2.imwrite(str(imgPath), res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse, Split and Save Dataset\n",
    "\n",
    "讀取所有設定路徑下的圖片，並將各個 class 的圖片以及對應的 class 依據前面設定的比例分割成 training dataset 以及 validation dataset，並寫入到指定的檔案中（TRAIN_LIST 以及 VALID_LIST）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into dict\n",
    "train_data = []\n",
    "valid_data = []\n",
    "\n",
    "\n",
    "NUM_CLASSES = 0\n",
    "CLASS_MAPPING = {}\n",
    "for index, subdir in enumerate(DATA_DIR.glob(\"*\")):\n",
    "\n",
    "    # iterate each file in this dir\n",
    "    image_list = []\n",
    "    for imgPath in subdir.glob(\"*\"):\n",
    "        image_list.append((Path.relative_to(imgPath, ROOT), index))\n",
    "\n",
    "    # split into train, validation list\n",
    "    tSize = math.floor(len(image_list)*(1-VALID_RATIO))\n",
    "\n",
    "    train_data += image_list[:tSize]\n",
    "    valid_data += image_list[tSize:]\n",
    "\n",
    "    # add label:class mapping\n",
    "    CLASS_MAPPING[NUM_CLASSES] = subdir.name\n",
    "\n",
    "    # count class\n",
    "    NUM_CLASSES += 1\n",
    "\n",
    "    # add NUM_CLASSES limit for faster testing\n",
    "    # if NUM_CLASSES > 30:\n",
    "    #     break\n",
    "\n",
    "\n",
    "# save to file\n",
    "with open(TRAIN_LIST, 'w') as f:\n",
    "    for img, cat in train_data:\n",
    "        f.write(f'{img} {cat}\\n')\n",
    "\n",
    "with open(VALID_LIST, 'w') as f:\n",
    "    for img, cat in valid_data:\n",
    "        f.write(f'{img} {cat}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightCNN(num_classes=NUM_CLASSES)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "設定 Training 以及 Validation 所需的 transforms 以及 data loader。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.RandomCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([.5], [.5])\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([.5], [.5])\n",
    "])\n",
    "\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(\n",
    "    ImageList(root=ROOT, fileList=TRAIN_LIST, transform=train_transform),\n",
    "    batch_size=BS,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKER,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    ImageList(root=ROOT, fileList=VALID_LIST, transform=valid_transform),\n",
    "    batch_size=BS,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKER,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train !\n",
    "\n",
    "開始 Train 以及 Validate，並紀錄每個 Epoch 的 avg loss 以及 avg accuracy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "helper = TrainingHelper(\n",
    "    train_dataloader=train_loader,\n",
    "    valid_dataloader=valid_loader,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BS,\n",
    "    learning_rate=LR,\n",
    "    print_frequency=PRINT_FREQUENCY,\n",
    "    model=model,\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam(params=model.parameters(), lr=LR)\n",
    ")\n",
    "\n",
    "for iEpoch in range(0, EPOCHS):\n",
    "\n",
    "    # train for one epoch\n",
    "    train_loss, train_acc = helper.train(iEpoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    valid_loss, valid_acc = helper.validate(iEpoch)\n",
    "\n",
    "    # log epoch result\n",
    "    helper.LOGGER.push(train_loss, train_acc, valid_loss, valid_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model and Show Result Graph ( Optional )\n",
    "\n",
    "儲存 model 到指定的路徑，並使用 Matplotlib 顯示各個 epoch 的 loss 以及 accuracy 的走向。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.LOGGER.visualize(loss_dst='loss.png', accuracy_dst='acc.png')\n",
    "helper.LOGGER.save(\"log.json\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
